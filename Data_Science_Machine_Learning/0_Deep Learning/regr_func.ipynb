{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c197be44",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "\n",
    "Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed3d59cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e94810b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1338, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>27.90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.9240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>33.77</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.5523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>33.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.4620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex    bmi  children  smoker     region     charges\n",
       "0   19    1  27.90         0       1  southwest  16884.9240\n",
       "1   18    0  33.77         1       0  southeast   1725.5523\n",
       "2   28    0  33.00         3       0  southeast   4449.4620"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('insurance.csv') #load the dataset\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "480dace9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['southwest', 'southeast', '0rthwest', '0rtheast'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect categorical features\n",
    "df.region.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e658652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['southwest', 'southeast', 'northwest', 'northeast'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean categorical features\n",
    "df.region = df.region.replace('0', 'no', regex=True)\n",
    "df.region.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdad3392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y\n",
    "X = df.iloc[:,0:6]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc965645",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>27.90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>33.77</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex    bmi  children  smoker  region_northeast  region_northwest  \\\n",
       "0   19    1  27.90         0       1                 0                 0   \n",
       "1   18    0  33.77         1       0                 0                 0   \n",
       "\n",
       "   region_southeast  region_southwest  \n",
       "0                 0                 1  \n",
       "1                 1                 0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot encoding for categorical variables\n",
    "X = pd.get_dummies(X) \n",
    "X.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a4c605",
   "metadata": {},
   "source": [
    "`Note:`\n",
    "\n",
    "Train,test, validation splits comes differently in terms of Neural Networks. Usually using traditional ML algorithm we do the process is to split a given data set into 70% train data set and 30% test data set (ideally). In the training phase, we fit the model on the training data. And now to evaluate the model (i.e., to check how well the model is able to predict on unseen data), we run the model against the test data and get the predicted results. Since we already know what the expected results are, we compare the predicted and the real results to get the accuracy of the model.\n",
    "If the accuracy is not up to the desired level, we repeat the above process (train, test, compare) until the desired accuracy is achieved.\n",
    "\n",
    "In Neural Networks approch, We do split our data set in train_test_plit(our test set) then we do spliting again our training set in fiting phase that will be our validation_set). Then finally we will test our model using the testing set(unseen data) and compare the predicted result to the real result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "534ee997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1070, 9) (268, 9) (1070,) (268,)\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state = 42)\n",
    "\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48d83c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac80a46",
   "metadata": {},
   "source": [
    "# Designing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f16d0506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a keras sequential object\n",
    "model_regr = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e3b7f8",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6692c270",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### INPUT LAYER\n",
    "model_regr.add(Dense(units = X.shape[1] , activation = 'relu')) \n",
    "\n",
    "\n",
    "#### HIDDEN LAYER 1\n",
    "# `Note:`\n",
    "# How do we choose the number of hidden layers and the number of units per layer? That is a tough question and there \n",
    "# is no good answer. The rule of thumb is to start with one hidden layer and add as many units as we have features in the\n",
    "# dataset. However, this might not always work. We need to try things out and observe our learning curve.\n",
    "\n",
    "# there are a numbers of activation functions such as softmax, sigmoid, \n",
    "# but ReLU (relu) (Rectified Linear Unit) is very effective in many applications and we’ll use it here.\n",
    "model_regr.add(Dense(128, activation = 'relu'))\n",
    "\n",
    "#### OUTPUT LAYER\n",
    "model_regr.add(Dense(1, activation = 'linear'))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b77e752",
   "metadata": {},
   "source": [
    "### OPTIMIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c80e8736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WE have a lot of optimizers such as SGD (Stochastic Gradient Descent optimizer), Adam, RMSprop, and others.\n",
    "# right now adam is the best one as its solved previous optmizers issues.\n",
    "opt = Adam(learning_rate = 0.01) # by default adam learning rate is 0.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bd85a1",
   "metadata": {},
   "source": [
    "### COMPILE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c2abd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss/cost \n",
    "# MSE, MAE, Huber loss  \n",
    "model_regr.compile(loss='mse',  metrics=['mae'], optimizer=opt)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd098a3",
   "metadata": {},
   "source": [
    "### FIT THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb471c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = model_regr.fit(x_train, y_train, \n",
    "               validation_split=0.2, \n",
    "               epochs=100, \n",
    "               batch_size=10,\n",
    "               verbose=1,\n",
    "#                callbacks=[stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbfef63",
   "metadata": {},
   "source": [
    "#### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00112b73",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# view summary\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel_regr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:2869\u001b[0m, in \u001b[0;36mModel.summary\u001b[1;34m(self, line_length, positions, print_fn, expand_nested, show_trainable)\u001b[0m\n\u001b[0;32m   2847\u001b[0m \u001b[38;5;124;03m\"\"\"Prints a string summary of the network.\u001b[39;00m\n\u001b[0;32m   2848\u001b[0m \n\u001b[0;32m   2849\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2866\u001b[0m \u001b[38;5;124;03m    ValueError: if `summary()` is called before the model is built.\u001b[39;00m\n\u001b[0;32m   2867\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2868\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt:\n\u001b[1;32m-> 2869\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2870\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis model has not yet been built. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2871\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBuild the model first by calling `build()` or by calling \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2872\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe model on a batch of data.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   2873\u001b[0m layer_utils\u001b[38;5;241m.\u001b[39mprint_summary(\n\u001b[0;32m   2874\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2875\u001b[0m     line_length\u001b[38;5;241m=\u001b[39mline_length,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2878\u001b[0m     expand_nested\u001b[38;5;241m=\u001b[39mexpand_nested,\n\u001b[0;32m   2879\u001b[0m     show_trainable\u001b[38;5;241m=\u001b[39mshow_trainable)\n",
      "\u001b[1;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."
     ]
    }
   ],
   "source": [
    "# view summary\n",
    "model_regr.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8e364e",
   "metadata": {},
   "source": [
    "#### Training Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2f5f53",
   "metadata": {},
   "source": [
    "Add early stoping when theres no improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c589ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference https://keras.io/api/callbacks/early_stopping/\n",
    "stop = EarlyStopping(monitor='val_loss', # validation_split 20%\n",
    "                     mode='min', \n",
    "                     patience=30,\n",
    "                     verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb977e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a variable to store our fitted model\n",
    "h = model_regr.fit(x_train, y_train, \n",
    "               validation_split=0.2, \n",
    "               epochs=100, \n",
    "               batch_size=10,\n",
    "               verbose=1,\n",
    "               callbacks=[stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9196066",
   "metadata": {},
   "outputs": [],
   "source": [
    "h.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2922c75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting\n",
    "\n",
    "fig, axs = plt.subplots(1,2,\n",
    "                        figsize=(15, 6),\n",
    "                        gridspec_kw={'hspace': 0.5, 'wspace': 0.2}) \n",
    "(ax1, ax2) = axs\n",
    "ax1.plot(h.history['loss'], label='Train')\n",
    "ax1.plot(h.history['val_loss'], label='Validation')\n",
    "ax1.set_title('learning rate=' + str(0.01))\n",
    "ax1.legend(loc=\"upper right\")\n",
    "ax1.set_xlabel(\"# of epochs\")\n",
    "ax1.set_ylabel(\"loss (MSE)\")\n",
    "\n",
    "ax2.plot(h.history['mae'], label='Train')\n",
    "ax2.plot(h.history['val_mae'], label='Validation')\n",
    "ax2.set_title('learning rate=' + str(0.01))\n",
    "ax2.legend(loc=\"upper right\")\n",
    "ax2.set_xlabel(\"# of epochs\")\n",
    "ax2.set_ylabel(\"MAE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bd0740",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f251a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_mse, val_mae = model_regr.evaluate(x_test, y_test, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1a1527",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "158ac4ff",
   "metadata": {},
   "source": [
    "# GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2eb7b9",
   "metadata": {},
   "source": [
    "### Function For Designing Model\n",
    "Function that creates and returns your Keras sequential model (To use in skires wrappers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f6f3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def design_model(features):\n",
    "  # ann model instance  \n",
    "  model_regr = Sequential()\n",
    "  \n",
    "  \n",
    "  #### INPUT LAYER>>>>\n",
    "  #adding the input layer\n",
    "  model_regr.add(Dense(units = X.shape[1] , activation = 'relu')) \n",
    "\n",
    "\n",
    "  #### HIDDEN LAYER1>>>>\n",
    "  # there are a numbers of activation functions such as softmax, sigmoid, \n",
    "  # but ReLU (relu) (Rectified Linear Unit) is very effective in many applications and we’ll use it here.\n",
    "  model_regr.add(Dense(128, activation = 'relu'))\n",
    "\n",
    "\n",
    "  #### OUTPUT LAYER>>>>\n",
    "  model_regr.add(Dense(1, activation = 'linear'))  \n",
    "\n",
    "\n",
    "  #### Optimizer\n",
    "  # WE have a lot of optimizers such as SGD (Stochastic Gradient Descent optimizer), Adam, RMSprop, and others.\n",
    "  # right now adam is the best one as its solved previous optmizers issues.\n",
    "  opt = Adam(learning_rate = 0.01)\n",
    "  # loss/cost \n",
    "  # MSE, MAE, Huber loss  \n",
    "  model_regr.compile(loss='mse',  metrics=['mae'], optimizer=opt)  \n",
    "    \n",
    "\n",
    "  return model_regr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b09400",
   "metadata": {},
   "source": [
    "Invoke our fucntion and pass the x_train argument then save it in a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b7c525",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_regr = design_model(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07de951",
   "metadata": {},
   "source": [
    "Fitting our training set to our `model_regr`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb722cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_regr.fit(x_train, y_train, \n",
    "               verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d8a5e3",
   "metadata": {},
   "source": [
    "To use KerasRegressor, we must define a function that creates and returns your Keras sequential model,(Above Function)\n",
    "then pass this function to the model argument when constructing the KerasClassifier class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c43b34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasRegressor(model = model_regr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c448a2",
   "metadata": {},
   "source": [
    "This is computational extensive, we will use small value here.\n",
    "\n",
    "List of hyperparameters:\n",
    " 1. the learning rate\n",
    " 2. number of batches\n",
    " 3. number of epochs\n",
    " 4. number of units per hidden layer\n",
    " 5. activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66339cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = dict(epochs = [50,100],\n",
    "                  batch_size = [1,10,50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44813e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=model, \n",
    "                    param_grid=param_grid,\n",
    "                    n_jobs=-1, # use all processor cores of our machine (faster!!)\n",
    "                    scoring = 'r2',\n",
    "                    return_train_score = True,\n",
    "                    cv=3)\n",
    "\n",
    "grid_result = grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fef2cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result.best_score_ , grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5767321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555f2cc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ebf171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fbbd14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f9c8b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386346de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a9d9674",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "\n",
    "1. Preparing the data for learning:\n",
    "2. separating features from labels using array slicing\n",
    "3. determining the shape of your data\n",
    "4. preprocessing the categorical variables using one-hot encoding\n",
    "5. splitting the data into training and test sets\n",
    "6. scaling the numerical features\n",
    "7. Designing a Sequential model by chaining InputLayer() and the tf.keras.layers.Dense layers. InputLayer() was used as a placeholder for the input data. The output layer in this case needed one neuron since we need a prediction of a single value in the regression. And finally, hidden layers were added with the relu activation function to handle complex dependencies in the data.\n",
    "8. Choosing an optimizer using keras.optimizers with a specific learning rate hyperparameter.\n",
    "9. Training the model - using model.fit() to train the model on the training data and training labels.\n",
    "10. Setting the values for the learning hyperparameters: number of epochs and batch sizes.\n",
    "11. Evaluating the model using model.evaluate() on the test data.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
